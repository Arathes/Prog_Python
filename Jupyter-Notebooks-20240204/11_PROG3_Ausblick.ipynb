{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Programmieren 3 - Grafik und GPU-Programmierung, Deep Learning\n",
    "\n",
    "Peter Rösch, Fakultät für Informatik\n",
    "\n",
    "Hochschule Augsburg, 2023/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Die Mandelbrotmenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Mandelbrotmenge wird an vielen Stellen beschrieben, einen Überblick finden Sie z.B. bei [Wikipedia](http://de.wikipedia.org/wiki/Mandelbrot-Menge).\n",
    "\n",
    "$$\n",
    "z_{n+1} = z^2_n + c, \\; z_0 = 0, \\; n < n_{\\rm max}, \\qquad {\\rm mit}\\quad z, c \\in \\mathbb{C}\n",
    "$$\n",
    "\n",
    "Wir wollen ein 2D-Bild berechnen, dessen Pixel jeweils einen bestimmten Wert für $ c\\,$ repräsentieren. Die Grauwerte entsprechen dem größten Wert $n$, für den an dieser Stelle gilt: $n < n_{\\rm max}$ und $|z_n| < 10$.\n",
    "\n",
    "Wir bilden zunächst den Bereich $c \\in [-2.5 - 1. 5i : 1.1 + 1.5 i]$ der komplexen Ebene auf ein Bild der Größe $1024 \\times 1024$ ab. \n",
    "\n",
    "**Fragen:** \n",
    "\n",
    "1. Warum ist die Berechnung dieses Bildes parallelisierbar?\n",
    "1. Wie sieht eine sinnvolle Aufteilung in Teilaufgaben aus?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jupyter: Vorbereitungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy (Arrays)\n",
    "import numpy as np\n",
    "# matplotlib (Ausgabe der Ergebnisse)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "# Groesse des zu berechnenden Bildes\n",
    "N = 1024\n",
    "s = (N, N)\n",
    "# Bereich (Realteil von -2.5 bis 1.1, Imaginaerteil -1.5 bis 1.5)\n",
    "rng = (-2.5, 1.1, -1.5, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CPU: Implementierung in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Quelle: Der Code basiert auf ein Beispiel von C. Rossant [1, Kap. 5]\n",
    "\n",
    "\n",
    "def mandelbrot_python(a, c_min=-2.5 - 1.5j, c_max=1.1 + 1.5j, n_max=100):\n",
    "    rng = c_max - c_min\n",
    "    scale_r = rng.real / a.shape[1]\n",
    "    scale_i = rng.imag / a.shape[0]\n",
    "    for y in range(a.shape[0]):\n",
    "        for x in range(a.shape[1]):\n",
    "            c = complex(c_min.real + x * scale_r, c_min.imag + y * scale_i)\n",
    "            z = 0\n",
    "            a[y, x] = n_max - 1\n",
    "            for n in range(n_max):\n",
    "                z = z * z + c\n",
    "                if abs(z) >= 10.0:\n",
    "                    a[y, x] = n\n",
    "                    break\n",
    "    return (c_min.real, c_max.real, c_min.imag, c_max.imag), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Test und Zeitmessung\n",
    "a_Python = np.zeros(shape=s, dtype=np.uint8)\n",
    "%timeit mandelbrot_python(a_Python)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ergebnis: AMD Ryzen 7 5800X\n",
    "\n",
    "1.57 s ± 5.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung der Ergebnisse\n",
    "ax = plt.figure(figsize=(10, 10)).add_subplot(111)\n",
    "ax.imshow(a_Python, extent=rng, origin=\"lower\", cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CPU: Beschleunigung mit *numba*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Quelle: Der Code basiert auf ein Beispiel von C. Rossant [1, Kap. 5]\n",
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def mandelbrot_numba(a, c_min=-2.5 - 1.5j, c_max=1.1 + 1.5j, n_max=100):\n",
    "    rng = c_max - c_min\n",
    "    scale_r = rng.real / a.shape[1]\n",
    "    scale_i = rng.imag / a.shape[0]\n",
    "    for y in prange(a.shape[0]):\n",
    "        for x in range(a.shape[1]):\n",
    "            c = complex(c_min.real + x * scale_r, c_min.imag + y * scale_i)\n",
    "            z = 0\n",
    "            a[y, x] = n_max - 1\n",
    "            for n in range(n_max):\n",
    "                z = z * z + c\n",
    "                if abs(z) >= 10.0:\n",
    "                    a[y, x] = n\n",
    "                    break\n",
    "    return (c_min.real, c_max.real, c_min.imag, c_max.imag), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Test und Zeitmessung\n",
    "a_numba = np.zeros(shape=s, dtype=np.uint8)\n",
    "%timeit mandelbrot_numba(a_numba)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ergebnis: AMD Ryzen 7 5800X\n",
    "\n",
    "36.1 ms ± 5.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Darstellung der Ergebnisse\n",
    "ax = plt.figure(figsize=(10, 10)).add_subplot(111)\n",
    "ax.imshow(a_numba, extent=rng, origin=\"lower\", cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# GPU: Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktuelle Grafikkarten bieten zumindest theoretisch eine höhere Rechenleistung als die CPU.\n",
    "\n",
    "**Nvidia GeForce RTX 4090:** 24GB, 1008 GB/s, 16384 Unified Shaders, ca. **82580/82580/1290 GFLOPS (FP16/FP32/FP64 prec.)**, 450 W (09/2022), siehe [TechPowerUp](https://www.techpowerup.com/gpu-specs/geforce-rtx-4090.c3889).\n",
    "\n",
    "**AMD Ryzen™ Threadripper™ 3990X:** 64 Kerne, 128 Threads,  2.9 GHz (Base) 4.3 GHz (max. Boost), **13200 GFLOPS (FP 32)**, 280 W (02/2020), siehe [TechPowerUp](https://www.techpowerup.com/cpu-specs/ryzen-threadripper-3990x.c2271).\n",
    "        \n",
    "**Cray 2:** ca. **2 GFLOPS**, 200 kW (Supercomputer, 1985), siehe [Wikipedia](https://en.m.wikipedia.org/wiki/Cray-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wie bringt man diese \"PS\" auf die Straße?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Architektur der GPU unterscheidet sich deutlich von der einer CPU, siehe z.B. [NVIDA Ampere](https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/), Details finden Sie im [Ampere Whitepaper, S. 12, Fig.3](https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf).\n",
    "\n",
    "Frage: Welche Auswirkungen hat das auf die Software-Entwicklung für GPUs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mögliche Vorgehensweise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Erstellung / Suchen einer CPU-Referenz-Implementierung\n",
    " 1. Den Algorithmus parallelisierbar (um)formulieren\n",
    " 1. Theoretische Vorüberlegungen zur Sinnhaftigkeit einer GPU-Implementierung (Bedarf an Zugriffen auf den globalen Speicher, Verhältnis Berechnungen/Speicherzugriffe, Identifikation von Flaschenhälsen)\n",
    " 1. Entwurf des Kernels, der Caching-Strategie, Überlegungen zur Block- und Grid-Größe, Entwicklung einer Test-Strategie\n",
    " 1. Implementierung und Test\n",
    "\n",
    "    [Details (NVIDIA)](http://docs.nvidia.com/cuda/cuda-c-programming-guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rechnen auf der GPU - Schritte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Initialisierung des Systems (OpenCL / CUDA / OpenGL / Vulkan).\n",
    " 1. Compilation des Rechen-Kernels.\n",
    " 1. Strukturierung der *threads* und *blocks* (*work-items* und *work-groups*).\n",
    " 1. Kopieren der Eingabe-Daten z.B. auf die Grafikkarte.\n",
    " 1. Aufruf des Kernels.\n",
    " 1. Kopieren der Ergebnisse in den Hauptspeicher oder direkte Visualisierung der Resultate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Der Kernel ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * muss herausfinden, für welche Eingabedaten er zuständig ist.\n",
    " * muss sicherstellen, dass er nicht über Array-Grenzen hinaus liest und schreibt.\n",
    " * ist oft auch für die Umsetzung der Caching-Strategie zuständig.\n",
    " * setzt Mechanismen wie z.B. *barriers* und *atomic add* zur Synchronisation ein.\n",
    " * wird millionenfach gestartet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mandelbrot auf der GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Verwendung von numba mit CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quellen: [NVIDIA](https://developer.nvidia.com/blog/numba-python-cuda-acceleration), [numba-Dokumentation](https://numba.readthedocs.io/en/stable/cuda/kernels.html)\n",
    "\n",
    "**Wichtig:** Falls keine NVIDIA-GPU vorhanden ist, kann der Cuda-Simulator von numba verwendet werden. Dazu muss die Umgebungsvariable [NUMBA_ENABLE_CUDASIM](https://numba.readthedocs.io/en/stable/reference/envvars.html) gesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def mandel_gpu(min_x, max_x, min_y, max_y, image, max_iters):\n",
    "    x_index, y_index = cuda.grid(2)\n",
    "\n",
    "    height, width = image.shape\n",
    "\n",
    "    if x_index < width and y_index < height:\n",
    "        pixel_size_x = (max_x - min_x) / width\n",
    "        pixel_size_y = (max_y - min_y) / height\n",
    "\n",
    "        x = min_x + x_index * pixel_size_x\n",
    "        y = min_y + y_index * pixel_size_y\n",
    "\n",
    "        c = complex(x, y)\n",
    "        z = 0.0j\n",
    "        image[y_index, x_index] = max_iters - 1\n",
    "        for i in range(max_iters):\n",
    "            z = z * z + c\n",
    "            if (z.real * z.real + z.imag * z.imag) >= 100:\n",
    "                image[y_index, x_index] = i\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "a_cuda = np.zeros(shape=s, dtype=np.uint8)\n",
    "threadsperblock = np.array([8, 8], dtype=np.uint32)\n",
    "blockspergrid = (a_cuda.shape + (threadsperblock - 1)) // threadsperblock\n",
    "mandel_gpu[tuple(blockspergrid), tuple(threadsperblock)](\n",
    "    -2.5, 1.1, -1.5, 1.5, a_cuda, 100\n",
    ")\n",
    "ax = plt.figure(figsize=(10, 10)).add_subplot(111)\n",
    "ax.imshow(a_cuda, extent=rng, origin=\"lower\", cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mandel_gpu[tuple(blockspergrid), tuple(threadsperblock)]\\\n",
    "          (-2.5, 1.1, -1.5, 1.5, a_cuda, 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnis (NVIDIA RTX A4000):\n",
    "\n",
    "1.89 ms ± 6.15 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Klassifikation von Bildern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Klassisches Beispiel: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Aufgabe:** Erkennung handgeschriebener Ziffern aus Bildern. \n",
    "* Eingabe: Grauwertbild, Größe 28 x 28 Pixel\n",
    "* Ausgabe: Ziffer (0-9).\n",
    "\n",
    "**Aufgabe verstehen:** [Typische Eingabebilder](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST mit Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Idee:** Merkmale (Features) und Regeln werde nicht explizit definiert und implementiert,\n",
    "sondern über die Parameter eines Netzwerks gelernt. Einige Wissenschaftler warnen\n",
    "vor der künstlichen Intelligenz, siehe z.B. [Will Knight in MIT technology review](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vorgehensweise: Maschinelles Lernen mittels neuronaler Netzwerke:\n",
    "1. Definition des Netzwerks (Schichten, Verbindungen).\n",
    "1. Erstellen großer annotierter Datensätze für Training und Evaluation.\n",
    "1. Training mit dem Ziel, einen Parametersatz zu finden, der die Anzahl der\n",
    "korrekten Klassifikationen maximiert.\n",
    "1. Verwendung des Models und der durch Training gefundenen Parameter für die\n",
    "Klassifikation unbekannter Datensätze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Links:**\n",
    "\n",
    "Vortrag von Martin Görner: [online](https://cloud.google.com/blog/products/gcp/learn-tensorflow-and-deep-learning-without-a-phd)\n",
    "    \n",
    "Wikipedia: https://en.wikipedia.org/wiki/Deep_learning\n",
    "\n",
    "Für die Bildverarbeitung (Wikipdia): [Convolutional Neural Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Werkzeuge (Auswahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow:** Von google entwickelte Open-source software-Bibliothek, die Python unterstützt und ab Version 2.0 auch [keras](https://keras.io) enthält. Die Installation mit\n",
    "anaconda ist einfach: conda install tensorflow oder conda install\n",
    "tensorflow-gpu, https://www.tensorflow.org\n",
    "\n",
    "**PyTorch:** Von Facebook entwickelte Bibliothek für maschinelles Lernen, siehe [Web-Seite](https://pytorch.org).\n",
    "\n",
    "**Spezialiserte Hardware:** [Google TPU](https://cloud.google.com/tpu), [Movedius Neural Compute Stick](https://newsroom.intel.com/news/intel-democratizes-deep-learning-application-development-launch-movidius-neural-compute-stick).\n",
    "\n",
    "Vergleich verschiedener Werkzeuge: [Wikipedia](https://en.wikipedia.org/wiki/comparison_of_deep_learning_software)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basis:** Tensorflow CNTK, Theano. In Tensorflow ab 2.x als tensorflow.keras enthalten.\n",
    "\n",
    "**Dokumentation:** [online](https://keras.io)\n",
    "\n",
    "**Relevanz:** Derzeit bei den [Kaggle Competitions](https://www.kaggle.com/competitions) erfolgreiches Framework.\n",
    "\n",
    "**Idee:** Vereinfache Schnittstelle zur Erstellung der für Tensorflow charakteristischen\n",
    "Datenflussgraphen.\n",
    "\n",
    "**GPU:** unterstützung über Tensorflow, cuda und [cudnn](https://developer.nvidia.com/cudnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:47:43.297576Z",
     "start_time": "2020-01-12T19:47:41.003860Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    module to load mnist data\n",
    "    Author: F. Chollet\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def get_mnist_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess mnist data.\n",
    "\n",
    "    Returns:\n",
    "        (train_images, train_labels, test_images, test_labels): tuple\n",
    "            normalised mnist data\n",
    "    \"\"\"\n",
    "    (train_images, train_labels), (\n",
    "        test_images,\n",
    "        test_labels,\n",
    "    ) = mnist.load_data()\n",
    "\n",
    "    # reshape and normalise\n",
    "    train_images = train_images.astype(\"float32\") / 255\n",
    "    train_labels = to_categorical(train_labels)\n",
    "\n",
    "    test_images = test_images.astype(\"float32\") / 255\n",
    "    test_labels = to_categorical(test_labels)\n",
    "\n",
    "    return (train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausführung der nächsten Zelle sollte auf Rechnern ohne GPU übersprungen werden ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:47:43.311915Z",
     "start_time": "2020-01-12T19:47:43.299132Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Author: F. Chollet\n",
    "# Die Ausführung auf der CPU dauert ...\n",
    "if True:\n",
    "    from tensorflow.keras import models\n",
    "    from tensorflow.keras.models import save_model\n",
    "    from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)\n",
    "\n",
    "    out_file_name = \"deep.hdf5\"\n",
    "    batch_size = 512\n",
    "    epochs = 10\n",
    "\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = (2, 2)\n",
    "    nb_filters = 32\n",
    "    input_shape = (28, 28, 1)\n",
    "\n",
    "    network = models.Sequential()\n",
    "    network.add(\n",
    "        Conv2D(\n",
    "            nb_filters,\n",
    "            kernel_size,\n",
    "            padding=\"valid\",\n",
    "            input_shape=input_shape,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    network.add(Conv2D(nb_filters, kernel_size, activation=\"relu\"))\n",
    "    network.add(MaxPooling2D(pool_size=pool_size))\n",
    "    network.add(Dropout(0.25))\n",
    "    network.add(Flatten())\n",
    "    network.add(Dense(128, activation=\"relu\"))\n",
    "    network.add(Dropout(0.5))\n",
    "    network.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    network.summary()\n",
    "\n",
    "    network.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    train_images, train_labels, test_images, test_labels = get_mnist_data()\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "    network.fit(train_images, train_labels, batch_size, epochs)\n",
    "    test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    # save model to disk\n",
    "    save_model(network, out_file_name, overwrite=True, include_optimizer=True)\n",
    "\n",
    "    print(\"test_loss: {}, test_acc: {}\".format(test_loss, test_acc))\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:47:49.048275Z",
     "start_time": "2020-01-12T19:47:43.313425Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_mnist_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "m = load_model(\"deep.hdf5\", compile=True)\n",
    "predicted_labels = m.predict(test_images, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Darstellung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:47:59.668341Z",
     "start_time": "2020-01-12T19:47:49.051077Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_labels)):\n",
    "    real_value = np.argmax(test_labels[i])\n",
    "    predicted_value = np.argmax(predicted_labels[i])\n",
    "    if real_value != predicted_value:\n",
    "        plt.title(\n",
    "            \"{} classified as {}\".format(\n",
    "                real_value,\n",
    "                predicted_value,\n",
    "            )\n",
    "        )\n",
    "        plt.imshow(test_images[i].reshape(28, 28), cmap=plt.cm.gray)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werde immer mehr vortrainierte Netze verwendet, die angepasst und dann z.B. in [OpenCV](https://docs.opencv.org/4.4.0/d6/d0f/group__dnn.html#gad820b280978d06773234ba6841e77e8d) geladen und dann direkt eingesetzt werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C. Rossant: *IPython Interactive Computing and Visualization Cookbook - Second Edition*, Packt Publishing [Online (O'Reilly)](https://learning.oreilly.com/library/view/ipython-interactive-computing/9781785888632).\n",
    "2. [Khronos (WebGL, Vulkan)](https://www.khronos.org)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "403px",
    "width": "574px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "487px",
    "left": "715px",
    "right": "168.667px",
    "top": "101px",
    "width": "716px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "933f1cd533ea252e98ac49ea74eb78c8e70183a514fda9ccc84d2ea69f19efdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
